{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a080c6-a67a-431d-84e9-64e06e43418a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from FlagEmbedding import FlagModel\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3aafa3ca-55cc-4ecd-a47d-fb4a9be7a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def remove_newline(text):\n",
    "# remove newline characters, \"\\n\", from the text\n",
    "# text: list of paragraphs in the text\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        text[i] = \" \".join(text[i].split())\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def embed_index_text(text_chunks, client):\n",
    "    # chunks: list of m elements that contain n sentences each\n",
    "    # client: instance of Elasticsearch client used to create the index\n",
    "\n",
    "    # embed chunks\n",
    "    chunk_embeddings = model.encode(text_chunks).tolist()\n",
    "\n",
    "    # define the format of the data to be indexed as pairs (chunk of text, chunk embeddings)\n",
    "    docs = [\n",
    "        {\n",
    "            '_op_type': 'index',\n",
    "            '_index': 'text_embeddings_index',\n",
    "            '_source': {\n",
    "                \"chunk\" : t, \n",
    "                \"embedding_vector\" : v\n",
    "            }\n",
    "        } for t, v in zip(text_chunks, chunks_embeddings)\n",
    "    ]\n",
    "    \n",
    "    # index in bulk\n",
    "    helpers.bulk(client, docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91c821-9313-4945-bc5f-e04be9a70968",
   "metadata": {},
   "source": [
    "### Read the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "90193364-37aa-4304-a8db-d0d2519ab9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/LesMiserables.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "385617a3-368f-4a51-8e7b-cfe700373d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file into one long string \"text\"\n",
    "with open(file_path, \"r\") as text_file:\n",
    "    text = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "92a6dcde-0596-4a8e-89df-e0ff8c7ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text by paragraphs \n",
    "text_paragraphs = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3dfa990c-05be-4dd9-81bb-460fce511f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14558"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "95c3b591-6190-4ed7-aad6-bf0fdc63cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the helper function \"remove_newline\" to eliminate \"\\n\" characters from the text\n",
    "\n",
    "text_paragraphs = remove_newline(text_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076e172-8be2-41e4-bb65-72f1e04e9bf9",
   "metadata": {},
   "source": [
    "The novel begins in paragraph 492 of the list. All contents that appear before this paragraph (i.e. paragraphs about project Gutenberg, publisher info, list of illustrations, and table of contents) are being removed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6ecddaa7-e1ae-49ff-8894-26a55715accc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LES MISÉRABLES',\n",
       " '',\n",
       " 'PREFACE',\n",
       " 'So long as there shall exist, by virtue of law and custom, decrees of damnation pronounced by society, artificially creating hells amid the civilization of earth, and adding the element of human fate to divine destiny; so long as the three great problems of the century—the degradation of man through pauperism, the corruption of woman through hunger, the crippling of children through lack of light—are unsolved; so long as social asphyxia is possible in any part of the world;—in other words, and with a still wider significance, so long as ignorance and poverty exist on earth, books of the nature of Les Misérables cannot fail to be of use.']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_paragraphs[492:496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1db72e43-4bfa-4a58-8421-8ce70a30f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered text, contains only the novel\n",
    "initial_paragraph = 492\n",
    "texts = text_paragraphs[initial_paragraph:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a744c-2175-4509-b175-4adde03c8fda",
   "metadata": {},
   "source": [
    "### Sentence segmentation using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003437d5-bc9b-4eb2-b594-f2aa10b8d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained English Language Model to separate the text into sentences\n",
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a862e09e-1540-4ad0-b9a3-ff6044eea3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object \"doc\" by creating an instance of the nlp class for one paragraph\n",
    "# when applying nlp to a text, spaCy tokenizes the text to produce a Doc object\n",
    "\n",
    "doc = nlp(text_paragraphs[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb5baa8b-e5c8-4916-9b03-85ffdb43aee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At the beginning of the Restoration, the convent of the Petit-Picpus was in its decay; this forms a part of the general death of the order, which, after the eighteenth century, has been disappearing like all the religious orders. Contemplation is, like prayer, one of humanity’s needs; but, like everything which the Revolution touched, it will be transformed, and from being hostile to social progress, it will become favorable to it.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af680e99-71fc-4b15-b021-32e1f5649236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print tokens and attributes in the doc\n",
    "# for token in doc:\n",
    "    # print(token.text, token.pos, token.dep, token.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3890dcca-f300-46ed-908d-ae2d3a103c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using entity recognizer in the text\n",
    "# for ent in doc.ents:\n",
    "#     print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a98a5950-357b-430f-9789-3b0e6f68a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence generator\n",
    "# doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f3b8f3d-56d4-4d21-af27-253e8901dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sentences when calling doc.sents (that generates tokens that point to each sentence in doc)\n",
    "# print each sentence in doc\n",
    "# for sent in doc.sents:\n",
    "#     print(sent)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1ab1e3db-9a52-4b2a-b269-7ca811a5a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LES MISÉRABLES',\n",
       " '',\n",
       " 'PREFACE',\n",
       " 'So long as there shall exist, by virtue of law and custom, decrees of damnation pronounced by society, artificially creating hells amid the civilization of earth, and adding the element of human fate to divine destiny; so long as the three great problems of the century—the degradation of man through pauperism, the corruption of woman through hunger, the crippling of children through lack of light—are unsolved; so long as social asphyxia is possible in any part of the world;—in other words, and with a still wider significance, so long as ignorance and poverty exist on earth, books of the nature of Les Misérables cannot fail to be of use.',\n",
       " 'HAUTEVILLE HOUSE, 1862.']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fea12d39-aa85-4ead-83cc-a1f72834887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bge language model to embed the text in chunks\n",
    "model = FlagModel('BAAI/bge-small-zh-v1.5', use_fp16 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "134ab184-1e44-439f-995e-3396a8a4e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# embedding single paragraphs\n",
    "embeddings_0 = model.encode(texts[0])\n",
    "embeddings_1 = model.encode(texts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f2500a90-f479-46a5-a09c-f44c4acd3bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f6319a9a-c57a-410a-be38-33016f345526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings_0.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8c3493fb-8d7d-4764-ae62-cff29b80bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarity between the embedded paragraphs\n",
    "similarity = embeddings_0 @ embeddings_1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e3cc0289-dc05-42a9-a1bf-2b1c8ae603a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.53408146)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0062a176-c65f-4c94-978e-0e490369844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Python client for Elastic search\n",
    "client = Elasticsearch(\"http://elasticsearch:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2506ae-8f32-4998-a48f-ea058a8bcd3a",
   "metadata": {},
   "source": [
    "Split the text into m chunks of n sentences. Once m chunks have been collected, embed the text using a pre-loaded LLM (BGE small in this case) and index the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "321217cf-7444-45ca-9638-d5a2050b7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a chunk is n sentences\n",
    "# every time I collect n sentences join them and that is a chunk, append to a list\n",
    "# after collecting m chunks, embed and index\n",
    "\n",
    "chunks = []\n",
    "sentences = []\n",
    "chunks_embeddings = []\n",
    "\n",
    "sentence_limit = 3\n",
    "chunk_limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1226ac17-55a5-4bb6-839c-07244098cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the format of index: chunk of text and embedding vectors\n",
    "# custom mapping that defines the expected types of indices features\n",
    "# define mapping parameters for the \"chunk\" and \"embedding_vector\" fields\n",
    "# define \"vector_dim\"\n",
    "\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"chunk\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"embedding_vector\": {\n",
    "            \"index\": True,\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 512,\n",
    "            \"similarity\": \"cosine\",\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7dbb35e5-3162-43f8-9978-b0fb71f51b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index called some_index using the defined mapping\n",
    "# client.indices.create(index = \"some_index\", mappings = mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a5373d4-3abc-41d0-a8a4-d1352211b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the index \"some_index\" exist?\n",
    "# client.indices.exists(index = \"some_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0103c4d7-6cc4-466b-97bf-34d772425bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete index called \"some_index\"\n",
    "# client.indices.delete(index = \"some_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9050fb2-a7ff-49f9-be4a-a212d6f5d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.index(\n",
    "#     index = \"some_index\",\n",
    "#     document = {\n",
    "#         \"chunk\": texts[0],\n",
    "#         \"embedding_vector\": embeddings_0.tolist(),\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b529296-5085-486a-8854-3b8d0402630c",
   "metadata": {},
   "source": [
    "Ensure that there is no previously created index with the name \"text_embeddings_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "22077a7a-fdcd-45c6-bb5e-557196eda45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (client.indices.exists(index = \"text_embeddings_index\")):\n",
    "    client.indices.delete(index = \"text_embeddings_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab712112-8269-4bc2-b1d5-24377b606b70",
   "metadata": {},
   "source": [
    "Create an Elasticsearch index, \"text_embeddings_index\", with the defined mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fa0ac9af-1257-4464-b894-7114e64fdb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'text_embeddings_index'})"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(index = \"text_embeddings_index\", mappings = mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed9eec-f831-4d82-8f38-9c81fcccff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the data as a stream and buffer the paragraphs in batches instead of one by one\n",
    "# calling nlp on a text returns a generator (doc_pipeline) that yields Doc objects\n",
    "doc_pipeline = nlp.pipe(texts, batch_size = 5, n_process = 1)\n",
    "\n",
    "for doc in doc_pipeline:\n",
    "    for sent in doc.sents:\n",
    "        sentences.append(sent.text)\n",
    "        \n",
    "        if len(sentences) == sentence_limit:\n",
    "            chunk = \" \".join(sentences)\n",
    "            chunks.append(chunk)\n",
    "            # remove the first sentence and keep the other two to overlap with the following sentence\n",
    "            sentences = sentences[1:]\n",
    "\n",
    "        if len(chunks) == chunk_limit:\n",
    "            # embed and index\n",
    "            embed_index_text(chunks, client)\n",
    "\n",
    "            # clear the list of chunks\n",
    "            chunks = []\n",
    "           \n",
    "    # print(doc.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e151aed2-8ebb-46ac-9def-6708590b44cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4148d19c-2e76-40f4-b470-8857d61acba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*** LES MISÉRABLES By Victor Hugo', 'LES MISÉRABLES By Victor Hugo']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "80c47314-6ca8-4585-9671-8e710421c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the end of the loop, verify if there are sentences/chunks left to embed and embed them\n",
    "if len(sentences) != 0:\n",
    "    # append sentences to remaining chunks\n",
    "    chunks.append(\" \".join(sentences))\n",
    "\n",
    "    embed_index_text(chunks, client)\n",
    "\n",
    "    sentences = []\n",
    "    chunks = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f9124096-07c5-471f-b556-6c8fa890c3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82dce63a-35af-4ae3-81bd-be430c6a39fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c03f16aa-9065-4071-b0cf-57f00ca3fa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextApiResponse('yellow open text_embeddings_index gzbxdOr-Sb2wQgT1ZPpzTw 1 1 0 0 227b 227b 227b\\n')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.cat.indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c4147f7d-6928-4784-b43e-458a7270d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'text_embeddings_index', '_id': 'yyWD0ZMBJCf2OsYv71ZF', '_score': 1.4960773, '_source': {'chunk': '*** LES MISÉRABLES By Victor Hugo'}}\n",
      "1.4960773 *** LES MISÉRABLES By Victor Hugo\n",
      "\n",
      "{'_index': 'text_embeddings_index', '_id': 'zCWD0ZMBJCf2OsYv71ZF', '_score': 1.4960773, '_source': {'chunk': 'LES MISÉRABLES By Victor Hugo'}}\n",
      "1.4960773 LES MISÉRABLES By Victor Hugo\n",
      "\n",
      "{'_index': 'text_embeddings_index', '_id': 'ySWD0ZMBJCf2OsYvpFbx', '_score': 1.289943, '_source': {'chunk': 'Title: Les Misérables Author: Victor Hugo Translator: Isabel Florence Hapgood'}}\n",
      "1.289943 Title: Les Misérables Author: Victor Hugo Translator: Isabel Florence Hapgood\n",
      "\n",
      "{'_index': 'text_embeddings_index', '_id': 'wyWD0ZMBJCf2OsYvo1Yi', '_score': 1.2225636, '_source': {'chunk': 'Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008'}}\n",
      "1.2225636 Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008\n",
      "\n",
      "{'_index': 'text_embeddings_index', '_id': 'yiWD0ZMBJCf2OsYvpFbx', '_score': 1.2225636, '_source': {'chunk': 'Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008'}}\n",
      "1.2225636 Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008\n",
      "\n",
      "{'_index': 'text_embeddings_index', '_id': 'yCWD0ZMBJCf2OsYvpFbx', '_score': 0.7895341, '_source': {'chunk': 'If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: Les Misérables Author: Victor Hugo'}}\n",
      "0.7895341 If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: Les Misérables Author: Victor Hugo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = client.search(\n",
    "    index = \"text_embeddings_index\",\n",
    "    query = {\n",
    "        \"bool\" : {\n",
    "            \"must\" : [\n",
    "                {\n",
    "                    \"match\" : {\n",
    "                    \"chunk\" : \"hugo\",\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"match\" : {\n",
    "                    \"chunk\" : \"victor\",\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    source = [\"chunk\"]\n",
    ")\n",
    "\n",
    "for hit in results[\"hits\"][\"hits\"]:\n",
    "\n",
    "    print(hit)\n",
    "    print(hit[\"_score\"], hit[\"_source\"][\"chunk\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "068fbb15-5a5a-4516-8e5b-98083b19ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': {'value': 6, 'relation': 'eq'},\n",
       " 'max_score': 1.4960773,\n",
       " 'hits': [{'_index': 'text_embeddings_index',\n",
       "   '_id': 'yyWD0ZMBJCf2OsYv71ZF',\n",
       "   '_score': 1.4960773,\n",
       "   '_source': {'chunk': '*** LES MISÉRABLES By Victor Hugo'}},\n",
       "  {'_index': 'text_embeddings_index',\n",
       "   '_id': 'zCWD0ZMBJCf2OsYv71ZF',\n",
       "   '_score': 1.4960773,\n",
       "   '_source': {'chunk': 'LES MISÉRABLES By Victor Hugo'}},\n",
       "  {'_index': 'text_embeddings_index',\n",
       "   '_id': 'ySWD0ZMBJCf2OsYvpFbx',\n",
       "   '_score': 1.289943,\n",
       "   '_source': {'chunk': 'Title: Les Misérables Author: Victor Hugo Translator: Isabel Florence Hapgood'}},\n",
       "  {'_index': 'text_embeddings_index',\n",
       "   '_id': 'wyWD0ZMBJCf2OsYvo1Yi',\n",
       "   '_score': 1.2225636,\n",
       "   '_source': {'chunk': 'Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008'}},\n",
       "  {'_index': 'text_embeddings_index',\n",
       "   '_id': 'yiWD0ZMBJCf2OsYvpFbx',\n",
       "   '_score': 1.2225636,\n",
       "   '_source': {'chunk': 'Author: Victor Hugo Translator: Isabel Florence Hapgood Release date: June 22, 2008'}},\n",
       "  {'_index': 'text_embeddings_index',\n",
       "   '_id': 'yCWD0ZMBJCf2OsYvpFbx',\n",
       "   '_score': 0.7895341,\n",
       "   '_source': {'chunk': 'If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: Les Misérables Author: Victor Hugo'}}]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da503c-dd06-4bd5-b1bd-f5f654f66384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
